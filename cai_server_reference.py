"""
FastAPI server that wraps CAI agents for task execution.

This server provides a simple HTTP API to execute cybersecurity tasks
using CAI agents (like bug_bounter_agent).

Usage:
    1. Set required environment variables (see below)
    2. Run: uvicorn fastapi_cai_server:app --reload --host 0.0.0.0 --port 4000
    3. POST to /complete_task with {"task_description": "your task"}

Environment Variables Required:
    - OPENAI_API_KEY or ALIAS_API_KEY: API key for the model provider
    - CAI_MODEL: Model to use (default: "alias0" or "claude-sonnet-4.5-20250929")
    - GOOGLE_SEARCH_API_KEY (optional): For web search capabilities
    - GOOGLE_SEARCH_CX (optional): Google Custom Search Engine ID
    - SHODAN_API_KEY (optional): For Shodan reconnaissance
"""

import os
import asyncio
from typing import Optional
from pathlib import Path
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# Load environment variables FIRST
load_dotenv()

# Create logs directory BEFORE importing CAI agents
Path("logs").mkdir(exist_ok=True)

# Import CAI components
from cai.sdk.agents import Runner, Agent, OpenAIChatCompletionsModel, set_tracing_disabled
from openai import AsyncOpenAI

# Disable tracing for performance (optional)
set_tracing_disabled(True)

# Import CAI pre-built agents (AFTER creating logs directory)
from cai.agents.bug_bounter import bug_bounter_agent
from cai.agents.red_teamer import redteam_agent

# Setup agent workspace
WORKSPACE_DIR = Path(__file__).parent / "agent_workspace"
WORKSPACE_DIR.mkdir(exist_ok=True)

# Create a README in the workspace
WORKSPACE_README = WORKSPACE_DIR / "README.md"
if not WORKSPACE_README.exists():
    WORKSPACE_README.write_text("""# Agent Workspace

This directory contains files generated by the CAI agents during task execution.

## Contents
- Python scripts for security testing
- SQL injection payloads
- Extracted data and reports
- Intermediate analysis files

## Usage
The agent automatically uses this directory for:
- Storing generated Python scripts
- Reading previously generated files
- Writing reports and outputs

You can safely examine, run, or delete these files.
""")

# Initialize FastAPI app
app = FastAPI(
    title="CAI Task Execution API",
    description="Execute cybersecurity tasks using CAI agents",
    version="1.0.0"
)

# Add CORS middleware to allow requests from frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins (for development)
    allow_credentials=True,
    allow_methods=["*"],  # Allow all methods
    allow_headers=["*"],  # Allow all headers
)

# Request/Response models
class TaskRequest(BaseModel):
    task_description: str
    model: Optional[str] = None  # Override default model if needed
    max_turns: Optional[int] = 50  # Maximum agent iterations

class TaskResponse(BaseModel):
    summary: str

# Agent mapping
AGENT_MAP = {
    "bug_bounty": bug_bounter_agent,
    "red_team": redteam_agent,
}

@app.get("/")
async def root():
    """Root endpoint - health check"""
    return {
        "status": "online",
        "service": "CAI Task Execution API",
        "available_agents": list(AGENT_MAP.keys())
    }

@app.get("/health")
async def health():
    """Health check endpoint"""
    return {"status": "healthy"}

@app.get("/agents")
async def list_agents():
    """List available agents"""
    return {
        "agents": [
            {
                "name": "red_team",
                "description": "Red team operations and penetration testing",
                "tools": ["nmap", "ssh_command", "netcat", "curl", "execute_code"]
            }
        ]
    }

@app.post("/complete_task", response_model=TaskResponse)
async def complete_task(request: TaskRequest):
    """
    Execute a cybersecurity task using CAI agents.

    Example request:
    {
        "task_description": "Fetch all usernames, first names, last names, password hashes from the users table on http://31.97.117.123/",
        "model": "claude-sonnet-4.5-20250929"
    }

    The agent will attempt to:
    1. Analyze the target URL
    2. Detect vulnerabilities (e.g., SQL injection)
    3. Exploit the vulnerability responsibly
    4. Extract requested data
    5. Return a summary of findings
    """
    try:
        # Always use red_team agent
        agent = AGENT_MAP["red_team"]

        # Override model if specified
        if request.model:
            # Create a new agent instance with custom model
            agent = Agent(
                name=agent.name,
                instructions=agent.instructions,
                description=agent.description,
                tools=agent.tools,
                input_guardrails=agent.input_guardrails,
                output_guardrails=agent.output_guardrails,
                model=OpenAIChatCompletionsModel(
                    model=request.model,
                    openai_client=AsyncOpenAI(),
                )
            )

        # Prepare context with workspace information
        workspace_context = {
            "workspace_dir": str(WORKSPACE_DIR.absolute()),
            "workspace_info": f"""
You have a dedicated workspace directory at: {WORKSPACE_DIR.absolute()}

This directory contains:
- Your previously generated scripts and files
- Output from previous executions
- Any data you've extracted

When using the execute_code tool:
1. Generated scripts will be saved in this workspace
2. You can access previously generated files by their names
3. All outputs should be written here

Use Python's os.chdir() to work in this directory, or use absolute paths.
"""
        }

        # NOTE: Don't change directory - let agent work with absolute paths
        # The workspace_dir is provided in context for the agent to use

        # Run the agent with the task and workspace context
        result = await Runner.run(
            starting_agent=agent,
            input=request.task_description,
            context=workspace_context,
            max_turns=request.max_turns
        )

        # Extract the summary from the result
        final_output = result.final_output

        # Format response
        if isinstance(final_output, str):
            summary = final_output
        else:
            summary = str(final_output)

        return TaskResponse(summary=summary)

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Task execution failed: {str(e)}"
        )

@app.post("/complete_task_stream")
async def complete_task_stream(request: TaskRequest):
    """
    Stream the task execution in real-time (SSE).

    This endpoint streams events as the agent executes the task,
    allowing clients to see progress in real-time.
    """
    from fastapi.responses import StreamingResponse
    import json

    async def event_generator():
        # Always use red_team agent
        agent = AGENT_MAP["red_team"]

        # Override model if specified
        if request.model:
            agent = Agent(
                name=agent.name,
                instructions=agent.instructions,
                description=agent.description,
                tools=agent.tools,
                input_guardrails=agent.input_guardrails,
                output_guardrails=agent.output_guardrails,
                model=OpenAIChatCompletionsModel(
                    model=request.model,
                    openai_client=AsyncOpenAI(),
                )
            )

        # Prepare context with workspace information
        workspace_context = {
            "workspace_dir": str(WORKSPACE_DIR.absolute()),
            "workspace_info": f"""
You have a dedicated workspace directory at: {WORKSPACE_DIR.absolute()}

This directory contains:
- Your previously generated scripts and files
- Output from previous executions
- Any data you've extracted

When using the execute_code tool:
1. Generated scripts will be saved in this workspace
2. You can access previously generated files by their names
3. All outputs should be written here

Use Python's os.chdir() to work in this directory, or use absolute paths.
"""
        }

        # NOTE: Don't change directory - let agent work with absolute paths
        # The workspace_dir is provided in context for the agent to use

        try:
            # Stream events
            result = Runner.run_streamed(
                starting_agent=agent,
                input=request.task_description,
                context=workspace_context,
                max_turns=request.max_turns
            )

            async for event in result.stream_events():
                # Convert event to JSON and send
                event_data = {
                    "type": event.__class__.__name__,
                    "data": str(event)
                }
                yield f"data: {json.dumps(event_data)}\n\n"
                await asyncio.sleep(0.01)  # Small delay for smooth streaming

            # Send final result
            final_data = {
                "type": "final",
                "summary": str(result.final_output),
                "success": True
            }
            yield f"data: {json.dumps(final_data)}\n\n"

        except Exception as e:
            error_data = {
                "type": "error",
                "error": str(e)
            }
            yield f"data: {json.dumps(error_data)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )

if __name__ == "__main__":
    import uvicorn

    # Check for required environment variables
    if not os.getenv("OPENAI_API_KEY") and not os.getenv("ALIAS_API_KEY"):
        print("WARNING: OPENAI_API_KEY or ALIAS_API_KEY not set!")
        print("Please set one of these environment variables before starting the server.")

    print("\n" + "="*60)
    print("Starting CAI Task Execution Server")
    print("="*60)
    print(f"Model: {os.getenv('CAI_MODEL', 'alias0')}")
    print(f"Available agents: {list(AGENT_MAP.keys())}")
    print("="*60 + "\n")

    uvicorn.run(app, host="0.0.0.0", port=4000)
